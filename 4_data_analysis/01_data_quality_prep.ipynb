{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37cc117b",
   "metadata": {},
   "source": [
    "# **Notebook Objective**\n",
    "\n",
    "**Description:**  \n",
    "This notebook serves as the first step in the data analysis pipeline.  \n",
    "Its primary purpose is to load the raw dataset (`clean_merged_data.csv`),  \n",
    "perform a thorough data quality audit, engineer new features essential for  \n",
    "the analysis (such as lags, rolling averages, and interaction terms), and  \n",
    "then export the cleaned and enriched data to a new file named  \n",
    "`analysis_ready_data.csv`. This new file will be the single source of truth  \n",
    "for all subsequent analysis notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0409b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define file paths\n",
    "# This assumes the notebook is in the '4_data_analysis' folder\n",
    "# and the data is in the '0_datasets' folder.\n",
    "input_file = Path(\"../1_datasets/final_datasets/clean_merged_data.csv\")\n",
    "output_file = Path(\"../0_datasets/analysis_ready_data.csv\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e673a5",
   "metadata": {},
   "source": [
    "### **Data Loading and Initial Inspection**\n",
    "\n",
    "**Description:**  \n",
    "This cell loads the dataset from the specified input file and performs a  \n",
    "high-level initial inspection. We check the dataset's dimensions (number of  \n",
    "rows and columns), list the column names, and display the first few rows to  \n",
    "get a feel for the data's structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1074c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from: ..\\1_datasets\\final_datasets\\clean_merged_data.csv\n",
      "--- Initial Inspection ---\n",
      "Dataset shape: (1950, 8)\n",
      "Columns: ['Country', 'Year', 'SDI', 'PM2.5', 'All-cause DALYs', 'Cardiovascular DALYs', 'Stroke DALYs', 'Respiratory DALYs']\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>SDI</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>All-cause DALYs</th>\n",
       "      <th>Cardiovascular DALYs</th>\n",
       "      <th>Stroke DALYs</th>\n",
       "      <th>Respiratory DALYs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.585824</td>\n",
       "      <td>14.14</td>\n",
       "      <td>2628.442345</td>\n",
       "      <td>907.907901</td>\n",
       "      <td>491.239471</td>\n",
       "      <td>209.815091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.591985</td>\n",
       "      <td>13.69</td>\n",
       "      <td>2631.550406</td>\n",
       "      <td>914.376036</td>\n",
       "      <td>491.661785</td>\n",
       "      <td>208.840770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.597740</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2565.804889</td>\n",
       "      <td>882.190695</td>\n",
       "      <td>471.917945</td>\n",
       "      <td>202.342766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.604065</td>\n",
       "      <td>12.81</td>\n",
       "      <td>2531.555083</td>\n",
       "      <td>867.937928</td>\n",
       "      <td>462.699749</td>\n",
       "      <td>198.976657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.610086</td>\n",
       "      <td>12.78</td>\n",
       "      <td>2478.617501</td>\n",
       "      <td>844.059254</td>\n",
       "      <td>448.100915</td>\n",
       "      <td>194.019144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country  Year       SDI  PM2.5  All-cause DALYs  Cardiovascular DALYs  \\\n",
       "0  Botswana  2010  0.585824  14.14      2628.442345            907.907901   \n",
       "1  Botswana  2011  0.591985  13.69      2631.550406            914.376036   \n",
       "2  Botswana  2012  0.597740  13.00      2565.804889            882.190695   \n",
       "3  Botswana  2013  0.604065  12.81      2531.555083            867.937928   \n",
       "4  Botswana  2014  0.610086  12.78      2478.617501            844.059254   \n",
       "\n",
       "   Stroke DALYs  Respiratory DALYs  \n",
       "0    491.239471         209.815091  \n",
       "1    491.661785         208.840770  \n",
       "2    471.917945         202.342766  \n",
       "3    462.699749         198.976657  \n",
       "4    448.100915         194.019144  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset loaded from: {input_file}\")\n",
    "print(\"--- Initial Inspection ---\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc0ef5",
   "metadata": {},
   "source": [
    "### **Data Quality Audit**\n",
    "\n",
    "**Description:**  \n",
    "This cell conducts a detailed data quality assessment to identify potential  \n",
    "issues. We check the data types of each column, count the number of missing  \n",
    "values, check for and count any duplicate rows, and verify that the 'Year'  \n",
    "column falls within our expected range (2010-2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9539a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Quality Audit ---\n",
      "\n",
      "Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Country               1950 non-null   object \n",
      " 1   Year                  1950 non-null   int64  \n",
      " 2   SDI                   1950 non-null   float64\n",
      " 3   PM2.5                 1950 non-null   float64\n",
      " 4   All-cause DALYs       1950 non-null   float64\n",
      " 5   Cardiovascular DALYs  1950 non-null   float64\n",
      " 6   Stroke DALYs          1950 non-null   float64\n",
      " 7   Respiratory DALYs     1950 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 122.0+ KB\n",
      "\n",
      "Missing Values per Column:\n",
      "Country                 0\n",
      "Year                    0\n",
      "SDI                     0\n",
      "PM2.5                   0\n",
      "All-cause DALYs         0\n",
      "Cardiovascular DALYs    0\n",
      "Stroke DALYs            0\n",
      "Respiratory DALYs       0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows found: 0\n",
      "Number of rows with Year outside 2010–2019: 0\n"
     ]
    }
   ],
   "source": [
    "# Perform a detailed data quality audit\n",
    "print(\"--- Data Quality Audit ---\")\n",
    "\n",
    "# Check data types and non-null counts\n",
    "print(\"\\nData Types and Non-Null Counts:\")\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows found: {num_duplicates}\")\n",
    "\n",
    "# Check for years outside the expected range\n",
    "invalid_years_count = df[\n",
    "    ~df['Year'].between(2010, 2019)\n",
    "].shape[0]\n",
    "print(\n",
    "    f\"Number of rows with Year outside 2010–2019: {invalid_years_count}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69471af",
   "metadata": {},
   "source": [
    "### **Feature Engineering**\n",
    "\n",
    "**Description:**  \n",
    "In this crucial step, we engineer new features to enhance the dataset  \n",
    "for modeling. This includes:\n",
    "\n",
    "1. **Sorting** the data by Country and Year to ensure correct time-series calculations.\n",
    "2. Creating **lag features** (`PM25_lag1`, `PM25_lag2`) to capture the effect  \n",
    "   of past pollution.\n",
    "3. Creating **rolling average features** (`PM25_3yr_avg`, `PM25_5yr_avg`)  \n",
    "   to model cumulative exposure.\n",
    "4. Creating an **interaction term** between PM₂.₅ and SDI to test if\n",
    "   development level modifies the pollution-health relationship.\n",
    "5. Creating a categorical variable for **SDI** to enable stratified analysis  \n",
    "   in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e2b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "Feature engineering complete.\n",
      "\n",
      "Sample of DataFrame with new features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>SDI</th>\n",
       "      <th>PM25_lag1</th>\n",
       "      <th>PM25_lag2</th>\n",
       "      <th>PM25_3yr_avg</th>\n",
       "      <th>PM25_5yr_avg</th>\n",
       "      <th>PM25_SDI_interaction</th>\n",
       "      <th>SDI_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>68.97</td>\n",
       "      <td>0.247760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.970000</td>\n",
       "      <td>68.970000</td>\n",
       "      <td>17.088004</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>66.94</td>\n",
       "      <td>0.257042</td>\n",
       "      <td>68.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.955000</td>\n",
       "      <td>67.955000</td>\n",
       "      <td>17.206370</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>68.26</td>\n",
       "      <td>0.266484</td>\n",
       "      <td>66.94</td>\n",
       "      <td>68.97</td>\n",
       "      <td>68.056667</td>\n",
       "      <td>68.056667</td>\n",
       "      <td>18.190226</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>72.18</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>68.26</td>\n",
       "      <td>66.94</td>\n",
       "      <td>69.126667</td>\n",
       "      <td>69.087500</td>\n",
       "      <td>19.895447</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>68.06</td>\n",
       "      <td>0.284030</td>\n",
       "      <td>72.18</td>\n",
       "      <td>68.26</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>68.882000</td>\n",
       "      <td>19.331106</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>67.20</td>\n",
       "      <td>0.291850</td>\n",
       "      <td>68.06</td>\n",
       "      <td>72.18</td>\n",
       "      <td>69.146667</td>\n",
       "      <td>68.528000</td>\n",
       "      <td>19.612287</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.299631</td>\n",
       "      <td>67.20</td>\n",
       "      <td>68.06</td>\n",
       "      <td>66.420000</td>\n",
       "      <td>67.940000</td>\n",
       "      <td>19.176365</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year  PM2.5       SDI  PM25_lag1  PM25_lag2  PM25_3yr_avg  \\\n",
       "0  Afghanistan  2010  68.97  0.247760        NaN        NaN     68.970000   \n",
       "1  Afghanistan  2011  66.94  0.257042      68.97        NaN     67.955000   \n",
       "2  Afghanistan  2012  68.26  0.266484      66.94      68.97     68.056667   \n",
       "3  Afghanistan  2013  72.18  0.275637      68.26      66.94     69.126667   \n",
       "4  Afghanistan  2014  68.06  0.284030      72.18      68.26     69.500000   \n",
       "5  Afghanistan  2015  67.20  0.291850      68.06      72.18     69.146667   \n",
       "6  Afghanistan  2016  64.00  0.299631      67.20      68.06     66.420000   \n",
       "\n",
       "   PM25_5yr_avg  PM25_SDI_interaction SDI_category  \n",
       "0     68.970000             17.088004          Low  \n",
       "1     67.955000             17.206370          Low  \n",
       "2     68.056667             18.190226          Low  \n",
       "3     69.087500             19.895447          Low  \n",
       "4     68.882000             19.331106          Low  \n",
       "5     68.528000             19.612287          Low  \n",
       "6     67.940000             19.176365          Low  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Feature Engineering ---\n",
    "print(\"Starting feature engineering...\")\n",
    "\n",
    "# Ensure data is sorted for time-series operations\n",
    "df = df.sort_values(['Country', 'Year']).reset_index(drop=True)\n",
    "\n",
    "# 1. Create 1-year and 2-year lag features for PM2.5\n",
    "df['PM25_lag1'] = df.groupby('Country')['PM2.5'].shift(1)\n",
    "df['PM25_lag2'] = df.groupby('Country')['PM2.5'].shift(2)\n",
    "\n",
    "# 2. Compute 3-year and 5-year rolling averages for PM2.5\n",
    "df['PM25_3yr_avg'] = (\n",
    "    df.groupby('Country')['PM2.5']\n",
    "      .rolling(window=3, min_periods=1)\n",
    "      .mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "df['PM25_5yr_avg'] = (\n",
    "    df.groupby('Country')['PM2.5']\n",
    "      .rolling(window=5, min_periods=1)\n",
    "      .mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# 3. Create interaction term: PM2.5 * SDI\n",
    "df['PM25_SDI_interaction'] = df['PM2.5'] * df['SDI']\n",
    "\n",
    "# 4. Create SDI categories for stratification\n",
    "sdi_bins = [0.0, 0.45, 0.61, 0.75, 1.0]\n",
    "sdi_labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "df['SDI_category'] = pd.cut(\n",
    "    df['SDI'],\n",
    "    bins=sdi_bins,\n",
    "    labels=sdi_labels,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Feature engineering complete.\")\n",
    "\n",
    "# Verify the new features by displaying a sample\n",
    "print(\"\\nSample of DataFrame with new features:\")\n",
    "new_features = [\n",
    "    'PM25_lag1', 'PM25_lag2', 'PM25_3yr_avg', 'PM25_5yr_avg',\n",
    "    'PM25_SDI_interaction', 'SDI_category'\n",
    "]\n",
    "display(df[['Country', 'Year', 'PM2.5', 'SDI'] + new_features].head(7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637bfc9",
   "metadata": {},
   "source": [
    "### **Export Processed Data**\n",
    "\n",
    "**Description:**  \n",
    "This final cell saves the fully cleaned and feature-enriched DataFrame  \n",
    "to a new CSV file. This `analysis_ready_data.csv` file will serve as  \n",
    "the input for all subsequent analytical notebooks, ensuring consistency  \n",
    "and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687622ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Export Complete ---\n",
      "Processed data with 14 columns saved to: ..\\0_datasets\\analysis_ready_data.csv\n",
      "Final shape of the analysis-ready data: (1950, 14)\n"
     ]
    }
   ],
   "source": [
    "# Export the processed DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"--- Export Complete ---\")\n",
    "print(\n",
    "    f\"Processed data with {df.shape[1]} columns saved to: {output_file}\"\n",
    ")\n",
    "print(f\"Final shape of the analysis-ready data: {df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data_Analysis_Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
