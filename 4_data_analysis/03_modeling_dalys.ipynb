{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9a2074",
   "metadata": {},
   "source": [
    "# **Notebook Objective**\n",
    "\n",
    "**Description:**\n",
    "The objective of this notebook is to train and evaluate regression models\n",
    "to predict the burden of disease (DALYs) based on PM₂.₅ exposure,\n",
    "socio-demographic development, and the engineered features. We will\n",
    "train two types of models—Linear Regression and Random Forest—for each\n",
    "of the four target DALY outcomes. The performance of these models will\n",
    "be evaluated, and the best-performing models (Random Forests) will be\n",
    "saved as artifacts for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dbb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib  # For saving/loading models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define file paths\n",
    "input_file = Path(\"../0_datasets/analysis_ready_data.csv\")\n",
    "model_dir = Path(\"../4_data_analysis/5_model_artifacts/\")\n",
    "metrics_file = Path(\n",
    "    \"../5_model_artifacts/model_performance_scores.csv\"\n",
    ")\n",
    "figure_dir = Path(\"../6_figures/model_diagnostics/\")\n",
    "\n",
    "# Ensure the output directories exist\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14b554",
   "metadata": {},
   "source": [
    "### **Load and Prepare Data for Modeling**\n",
    "\n",
    "**Description:**\n",
    "This cell loads the `analysis_ready_data.csv` and prepares it for\n",
    "modeling. We define our predictor (independent) and target (dependent)\n",
    "variables. A final modeling DataFrame is created by dropping any rows\n",
    "that have missing values in the selected columns, which is a necessary\n",
    "step as regression models cannot handle `NaN` inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564fef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: ..\\0_datasets\\analysis_ready_data.csv\n",
      "\n",
      "Original DataFrame shape: (1950, 14)\n",
      "Shape after dropping NaNs for modeling: (1560, 11)\n",
      "Number of rows dropped: 390\n",
      "\n",
      "Feature matrix (X) for modeling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>SDI</th>\n",
       "      <th>PM25_lag1</th>\n",
       "      <th>PM25_lag2</th>\n",
       "      <th>PM25_3yr_avg</th>\n",
       "      <th>PM25_5yr_avg</th>\n",
       "      <th>PM25_SDI_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.26</td>\n",
       "      <td>0.266484</td>\n",
       "      <td>66.94</td>\n",
       "      <td>68.97</td>\n",
       "      <td>68.056667</td>\n",
       "      <td>68.056667</td>\n",
       "      <td>18.190226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.18</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>68.26</td>\n",
       "      <td>66.94</td>\n",
       "      <td>69.126667</td>\n",
       "      <td>69.087500</td>\n",
       "      <td>19.895447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.06</td>\n",
       "      <td>0.284030</td>\n",
       "      <td>72.18</td>\n",
       "      <td>68.26</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>68.882000</td>\n",
       "      <td>19.331106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.20</td>\n",
       "      <td>0.291850</td>\n",
       "      <td>68.06</td>\n",
       "      <td>72.18</td>\n",
       "      <td>69.146667</td>\n",
       "      <td>68.528000</td>\n",
       "      <td>19.612287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.00</td>\n",
       "      <td>0.299631</td>\n",
       "      <td>67.20</td>\n",
       "      <td>68.06</td>\n",
       "      <td>66.420000</td>\n",
       "      <td>67.940000</td>\n",
       "      <td>19.176365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PM2.5       SDI  PM25_lag1  PM25_lag2  PM25_3yr_avg  PM25_5yr_avg  \\\n",
       "0  68.26  0.266484      66.94      68.97     68.056667     68.056667   \n",
       "1  72.18  0.275637      68.26      66.94     69.126667     69.087500   \n",
       "2  68.06  0.284030      72.18      68.26     69.500000     68.882000   \n",
       "3  67.20  0.291850      68.06      72.18     69.146667     68.528000   \n",
       "4  64.00  0.299631      67.20      68.06     66.420000     67.940000   \n",
       "\n",
       "   PM25_SDI_interaction  \n",
       "0             18.190226  \n",
       "1             19.895447  \n",
       "2             19.331106  \n",
       "3             19.612287  \n",
       "4             19.176365  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the analysis-ready dataset\n",
    "try:\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Successfully loaded data from: {input_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_file} was not found.\")\n",
    "    print(\"Please run '01_data_quality_prep.ipynb' first.\")\n",
    "    print(\"Then run '02_exploratory_trends.ipynb'.\")\n",
    "\n",
    "# 2.1 Define predictor and target variables\n",
    "predictor_vars = [\n",
    "    'PM2.5',\n",
    "    'SDI',\n",
    "    'PM25_lag1',\n",
    "    'PM25_lag2',\n",
    "    'PM25_3yr_avg',\n",
    "    'PM25_5yr_avg',\n",
    "    'PM25_SDI_interaction'\n",
    "]\n",
    "\n",
    "target_vars = [\n",
    "    'All-cause DALYs',\n",
    "    'Cardiovascular DALYs',\n",
    "    'Stroke DALYs',\n",
    "    'Respiratory DALYs'\n",
    "]\n",
    "\n",
    "# 2.2 Create the final modeling dataframe by dropping NaNs\n",
    "all_model_vars = predictor_vars + target_vars\n",
    "model_df = df[all_model_vars].dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nOriginal DataFrame shape: {df.shape}\")\n",
    "print(f\"Shape after dropping NaNs for modeling: {model_df.shape}\")\n",
    "print(f\"Number of rows dropped: {df.shape[0] - model_df.shape[0]}\")\n",
    "\n",
    "# 2.3 Separate features (X) and create a dictionary of targets (y)\n",
    "X = model_df[predictor_vars]\n",
    "y_dict = {target: model_df[target] for target in target_vars}\n",
    "\n",
    "# Display the first few rows of the feature matrix to verify\n",
    "print(\"\\nFeature matrix (X) for modeling:\")\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581b963",
   "metadata": {},
   "source": [
    "### **Code Cell 3: Train, Evaluate, and Save Models**\n",
    "\n",
    "**Description:**\n",
    "This is the core modeling cell. It iterates through each of the four DALY\n",
    "outcomes. For each outcome, it performs the following actions:\n",
    "\n",
    "1. Splits the data into training (80%) and testing (20%) sets.\n",
    "2. Trains both a Linear Regression and a Random Forest Regressor model.\n",
    "3. Evaluates each model's performance on the test set using R-squared\n",
    "   (R²) and Root Mean Squared Error (RMSE).\n",
    "4. Saves the trained Random Forest model to a `.pkl` file in the\n",
    "   `5_model_artifacts` directory for later use.\n",
    "5. Stores the performance metrics in a dictionary for summary reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store results and trained models\n",
    "model_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "# Loop through each target variable to train and evaluate models\n",
    "for target_name, y in y_dict.items():\n",
    "    print(f\"\\n--- Modeling for: {target_name} ---\")\n",
    "\n",
    "    # 1. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 2. Define models to train\n",
    "    models_to_train = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Initialize nested dictionaries\n",
    "    model_results[target_name] = {}\n",
    "    trained_models[target_name] = {}\n",
    "\n",
    "    for model_name, model in models_to_train.items():\n",
    "        # 3. Train the model\n",
    "        print(f\"Training {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # 4. Make predictions and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # 5. Store results and the trained model instance\n",
    "        model_results[target_name][model_name] = {'R²': r2, 'RMSE': rmse}\n",
    "        trained_models[target_name][model_name] = model\n",
    "        print(f\"  {model_name} -> R²: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # 6. Save the best model (Random Forest) to a file\n",
    "    rf_model_to_save = trained_models[target_name]['Random Forest']\n",
    "    model_filename = model_dir / (\n",
    "        f\"rf_model_{target_name.replace(' ', '_').lower()}.pkl\"\n",
    "    )\n",
    "    joblib.dump(rf_model_to_save, model_filename)\n",
    "    print(f\"  Saved Random Forest model to: {model_filename}\")\n",
    "\n",
    "print(\"\\n--- Model training and saving complete. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb99bce",
   "metadata": {},
   "source": [
    "### **Code Cell 4: Compile and Save Performance Metrics**\n",
    "\n",
    "**Description:**\n",
    "This cell takes the performance metrics collected in the previous step,\n",
    "compiles them into a clean and readable pandas DataFrame, and saves this\n",
    "summary table to a CSV file. This creates a persistent record of the\n",
    "model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the nested dictionary of results\n",
    "results_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): model_results[i][j]\n",
    "        for i in model_results.keys()\n",
    "        for j in model_results[i].keys()\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "results_df.index.names = ['DALY Outcome', 'Model']\n",
    "\n",
    "print(\"--- Summary of Model Performance ---\")\n",
    "display(results_df)\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "try:\n",
    "    results_df.to_csv(metrics_file)\n",
    "    print(\n",
    "        f\"\\nSuccessfully saved model performance metrics to: {metrics_file}\"    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the metrics file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd52c47",
   "metadata": {},
   "source": [
    "### **Code Cell 5: Residual Analysis and Diagnostic Plots**\n",
    "\n",
    "**Description:**\n",
    "This final cell performs a visual diagnosis of the best-performing models\n",
    "(Random Forests). For each DALY outcome, it generates two critical plots:\n",
    "\n",
    "1. **Predictions vs. Actual Plot:** Helps assess overall accuracy. A\n",
    "   perfect model would have all points on the 45-degree diagonal line.2. **Residuals vs. Predicted Plot:** Helps identify systematic errors. The\n",
    "   errors (residuals) should be randomly scattered around zero with no\n",
    "   discernible pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ae543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance for the better model (Random Forest)\n",
    "print(\"\\n--- Generating Diagnostic Plots for Random Forest Models ---\")\n",
    "\n",
    "for target_name, models in trained_models.items():\n",
    "    print(f\"Processing diagnostics for: {target_name}\")\n",
    "\n",
    "    # Select the RF model and corresponding data\n",
    "    rf_model = models['Random Forest']\n",
    "    # Regenerate test split to ensure correct data alignment\n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "        X, y_dict[target_name], test_size=0.2, random_state=42\n",
    "    )\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    # Create subplot for diagnostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    fig.suptitle(\n",
    "        f'Diagnostic Plots for {target_name} (Random Forest)', fontsize=16\n",
    "    )\n",
    "\n",
    "    # 1. Predictions vs. Actual Plot\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, ax=axes[0])\n",
    "    axes[0].plot(\n",
    "        [y_test.min(), y_test.max()],\n",
    "        [y_test.min(), y_test.max()],\n",
    "        '--', color='red', lw=2\n",
    "    )\n",
    "    axes[0].set_title('Predictions vs. Actual Values')\n",
    "    axes[0].set_xlabel('Actual DALYs')\n",
    "    axes[0].set_ylabel('Predicted DALYs')\n",
    "\n",
    "    # 2. Residuals vs. Predicted Plot\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.6, ax=axes[1])\n",
    "    axes[1].axhline(0, linestyle='--', color='red', lw=2)\n",
    "    axes[1].set_title('Residuals vs. Predicted Values')\n",
    "    axes[1].set_xlabel('Predicted DALYs')\n",
    "    axes[1].set_ylabel('Residuals (Error)')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\n",
    "        figure_dir / f\"diag_plots_{target_name.replace(' ', '_').lower()}.png\"\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "03_modeling_dalys.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
